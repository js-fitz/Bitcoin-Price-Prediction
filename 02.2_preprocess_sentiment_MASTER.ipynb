{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import flair\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Null Value Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removenull(df):\n",
    "    if df['title'].isnull().sum() != 0:\n",
    "        df.dropna(subset=['title'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textcombine(df):\n",
    "    df['title_and_text'] = ''\n",
    "    for i in range(0, len(df['title'])):\n",
    "        if pd.isnull(df['selftext'][i]) == True:\n",
    "            df['title_and_text'][i] = df['title'][i]\n",
    "        elif df['selftext'][i] == '[removed]':\n",
    "            df['title_and_text'][i] = df['title'][i]\n",
    "        else:\n",
    "            df['title_and_text'][i] = df['title'][i] + ' ' + df['selftext'][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(df, column):\n",
    "    for i in range(len(df)):\n",
    "\n",
    "        review_text = str(BeautifulSoup(df[column][i]).get_text())\n",
    "\n",
    "        letters_only = re.sub(\"[^a-zA-Z0-9]\", \" \", review_text)\n",
    "\n",
    "\n",
    "        words = letters_only.lower().split()\n",
    "\n",
    "        stops = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "        meaningful_words = [w for w in words if w not in stops]\n",
    "\n",
    "        df[column][i] = \" \".join(meaningful_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Sentiment Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_score(df, column):\n",
    "    \n",
    "    df[\"vader_neu_score\"] = \"\"\n",
    "    df[\"vader_pos_score\"] = \"\"\n",
    "    df[\"vader_neg_score\"] = \"\"\n",
    "    df[\"vader_compound\"] = \"\"\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        sent_dict = sid.polarity_scores(df[column][i])\n",
    "        df[\"vader_neg_score\"][i] = sent_dict['neg']\n",
    "        df[\"vader_neu_score\"][i] = sent_dict['neu']\n",
    "        df[\"vader_pos_score\"][i] = sent_dict['pos']\n",
    "        df[\"vader_compound\"][i] = sent_dict['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_score(df, column):\n",
    "    \n",
    "    df['blob_polarity'] = ''\n",
    "    df['blob_subjectivity'] = ''\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        blob = TextBlob(df[column][i])\n",
    "        df['blob_polarity'][i] = blob.sentiment[0]\n",
    "        df['blob_subjectivity'][i] = blob.sentiment[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flair_score(df, column):\n",
    "    \n",
    "    flair_sentiment = flair.models.TextClassifier.load('en-sentiment')\n",
    "    df['flair_polarity'] = \"\"\n",
    "    df['flair_score'] = \"\"\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        s = flair.data.Sentence(df[column][i])\n",
    "        flair_sentiment.predict(s)\n",
    "        total_sentiment = s.labels\n",
    "        total_sentiment\n",
    "        df['flair_polarity'][i] = str(total_sentiment[0]).split(' (')[0]\n",
    "        df['flair_score'][i] = (str(total_sentiment[0]).split(' (')[1].split(')')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Markup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_senti(df):\n",
    "    \n",
    "    df['neu_score'] = df['neu_score'].astype(str).astype(float)\n",
    "    df['pos_score'] = df['pos_score'].astype(str).astype(float)\n",
    "    df['neg_score'] = df['neg_score'].astype(str).astype(float)\n",
    "    df['compound'] = df['compound'].astype(str).astype(float)\n",
    "    \n",
    "    mean_df = df.groupby('Date').agg('mean')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Post Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_sum(df):\n",
    "    \n",
    "    df['Sum_posts'] = 1\n",
    "    \n",
    "    sum_df = df.groupby('Date').agg('sum')\n",
    "    sum_df.drop(columns = sum_df.columns[:-1], inplace = True)\n",
    "    sum_df['zip_code'] = sum_df.index\n",
    "    df2 = pd.merge(df, sum_df, left_index = True, right_index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
