{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook is to loop through the imports of the scrapped data off pushshift.io and to export it to csv_files. The code in this Notebook is not too important, as I added and deleted certain specific commands. This is the general template for exportation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import threading\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Model Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1561521600, 1561780800, 86400):\n",
    "    params = {\n",
    "        'subreddit': 'Bitcoin',\n",
    "        'size': 2000,\n",
    "        'after': i\n",
    "    }\n",
    "    res = requests.get(url, params)\n",
    "    bit_data = res.json()\n",
    "    bit_posts = bit_data['data']\n",
    "    bit = pd.DataFrame(bit_posts)\n",
    "    bit = bit[['subreddit', 'created_utc', 'title', 'selftext', 'score']]\n",
    "    bit.to_csv('./Reddit_Data/2019/Missing' + str(counter) + '_2019.csv')\n",
    "    counter += 1\n",
    "    time.sleep(62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1577854800, 1583643600, 172800):\n",
    "    params = {\n",
    "        'subreddit': 'Bitcoin',\n",
    "        'size': 2000,\n",
    "        'after': i\n",
    "    }\n",
    "    res = requests.get(url, params)\n",
    "    bit_data = res.json()\n",
    "    bit_posts = bit_data['data']\n",
    "    bit = pd.DataFrame(bit_posts)\n",
    "    bit = bit[['subreddit', 'created_utc', 'title', 'selftext', 'score']]\n",
    "    bit.to_csv('./Reddit_Data/2020/Missing' + str(counter) + '_2020.csv')\n",
    "    counter += 1\n",
    "    time.sleep(62)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
